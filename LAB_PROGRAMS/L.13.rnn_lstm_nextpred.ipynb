{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y_nssai1C6F9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import TextVectorization, Embedding, SimpleRNN, Dense\n",
    "from keras import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQP8U7r5F4Yd"
   },
   "source": [
    "# Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kdsfH2rJC6GA"
   },
   "outputs": [],
   "source": [
    "text=\"This is a sample text used to demonstrate predictive text with basic RNNs.In this example,we'll predict the next word as you type \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B5uiDuwHDORO"
   },
   "outputs": [],
   "source": [
    "tokenizer = TextVectorization()\n",
    "tokenizer.adapt(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxBRtZYZD34x",
    "outputId": "fa9ee5e5-ad85-480e-dda3-d64c59350cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int64, numpy=\n",
       "array([ 2, 16, 21, 11,  3,  7,  9, 18, 13,  3,  6, 19, 12,  2, 17, 14, 10,\n",
       "       15,  5, 20,  4,  8], dtype=int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences = tokenizer(text)\n",
    "text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FHf2LmhgD7jm"
   },
   "outputs": [],
   "source": [
    "x = text_sequences[:-1]\n",
    "y = text_sequences[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MON6K656ESje"
   },
   "source": [
    "`text_sequences[:-1]` is slicing the list of text sequences to create `x`. It *takes all elements from the beginning of the list to the second-to-last element*. This means it creates x with all sequences except the last one.\n",
    "\n",
    "`text_sequences[1:]` is slicing the list of text sequences to create `y`. It *takes all elements starting from the second element to the end of the list*. This means it creates y with all sequences except the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TZXhQ4eAEy-W"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.get_vocabulary()), output_dim=64, input_length=1),\n",
    "    SimpleRNN(128,return_sequences=True),\n",
    "    Dense(len(tokenizer.get_vocabulary()),activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N0VoQofoFLMu"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obClzTmVFM69",
    "outputId": "0b49cc65-90eb-4976-9b14-3a0d1e924164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 3.0946\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0805\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0664\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0523\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0381\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0240\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0097\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9953\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9808\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9660\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9510\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9357\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9201\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9041\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8877\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8709\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8536\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8358\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8175\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7986\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7790\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7589\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7380\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7164\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6942\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6711\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6472\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.6226\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5971\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5707\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5434\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5153\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4862\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4561\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4251\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3931\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3601\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3262\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2912\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2552\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2182\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1802\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1412\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1012\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0602\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0183\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9755\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9317\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8871\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1132425f5e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zlg714FfFN_-"
   },
   "outputs": [],
   "source": [
    "def generate_next_word(seed_text):\n",
    "  seed_sequence=tokenizer(seed_text)\n",
    "  predicted_probabilities=model.predict(seed_sequence)\n",
    "  predicted_index=np.argmax(predicted_probabilities)\n",
    "  predicted_word=tokenizer.get_vocabulary()[predicted_index]\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xq8aXPQ7Fdnm",
    "outputId": "6d47ab18-c89e-44a8-a743-aa607be33bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "Input: 'used', Predicted: 'to'\n"
     ]
    }
   ],
   "source": [
    "input_text = \"used\"\n",
    "predicted_word = generate_next_word(input_text)\n",
    "print(f\"Input: '{input_text}', Predicted: '{predicted_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX6PjwI3F0h3"
   },
   "source": [
    "# Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vY3KsCqMGTS2"
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VbiY4eBAGJQS"
   },
   "outputs": [],
   "source": [
    "text=\"This is a sample text used to demonstrate predictive text with basic LSTM.In this example,we'll predict the next word as you type \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GigB4f4jGJQZ"
   },
   "outputs": [],
   "source": [
    "tokenizer = TextVectorization()\n",
    "tokenizer.adapt(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4A6YKSYGJQZ",
    "outputId": "2e3267f8-1171-4705-e480-5ea11b70a0e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int64, numpy=\n",
       "array([ 2, 16, 21, 11,  3,  7,  9, 18, 12,  3,  6, 19, 15,  2, 17, 13, 10,\n",
       "       14,  5, 20,  4,  8], dtype=int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences = tokenizer(text)\n",
    "text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-lzDDLFGGJQZ"
   },
   "outputs": [],
   "source": [
    "x = text_sequences[:-1]\n",
    "y = text_sequences[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmkuGQNTGJQZ"
   },
   "source": [
    "`text_sequences[:-1]` is slicing the list of text sequences to create `x`. It *takes all elements from the beginning of the list to the second-to-last element*. This means it creates x with all sequences except the last one.\n",
    "\n",
    "`text_sequences[1:]` is slicing the list of text sequences to create `y`. It *takes all elements starting from the second element to the end of the list*. This means it creates y with all sequences except the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G-ZH3BaoGJQa"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.get_vocabulary()), output_dim=64, input_length=1),\n",
    "    LSTM(128,return_sequences=True),\n",
    "    Dense(len(tokenizer.get_vocabulary()),activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Hm_U2syMGJQa"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtVrbi3VGJQa",
    "outputId": "0d1284c8-4d8d-4741-9d5c-5432aa7dc183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 3.0903\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0875\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0847\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0818\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0789\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0759\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0729\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0698\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0667\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0635\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0602\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0567\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0532\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0495\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0457\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0418\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0376\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0333\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0289\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0242\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0193\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0142\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0089\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0033\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9975\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9914\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9850\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9783\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9713\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9640\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9563\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9483\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9399\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9311\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9219\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9122\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9022\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8916\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8806\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8690\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8569\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8443\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8312\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8174\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8030\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7880\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7724\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7561\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7391\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x113266149d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Suzq22uIGJQa"
   },
   "outputs": [],
   "source": [
    "def generate_next_word(seed_text):\n",
    "  seed_sequence=tokenizer(seed_text)\n",
    "  predicted_probabilities=model.predict(seed_sequence)\n",
    "  predicted_index=np.argmax(predicted_probabilities)\n",
    "  predicted_word=tokenizer.get_vocabulary()[predicted_index]\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJdT3arLGJQb",
    "outputId": "14f86dce-0731-4c9e-ce8b-afd45f973cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "Input: 'this', Predicted: 'is'\n"
     ]
    }
   ],
   "source": [
    "input_text = \"this\"\n",
    "predicted_word = generate_next_word(input_text)\n",
    "print(f\"Input: '{input_text}', Predicted: '{predicted_word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
